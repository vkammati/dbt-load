
# Name your project! Project names should contain only lowercase characters
# and underscores. A good package name should reflect your organization's
# name or the intended use of these models
name: 'dbt_transform'
version: '1.0.0'
config-version: 2

# This setting configures which "profile" dbt uses for this project.
profile: 'dbt_transform'

# These configurations specify where dbt should look for different types of files.
# The `model-paths` config, for example, states that models in this project can be
# found in the "models/" directory. You probably won't need to change these!
model-paths: ["models"]
analysis-paths: ["analyses"]
test-paths: ["tests"]
seed-paths: ["seeds"]
macro-paths: ["macros"]
snapshot-paths: ["snapshots"]

clean-targets:         # directories to be removed by `dbt clean`
  - "target"
  - "dbt_packages"
  - "logs"

# Configuring models
# Full documentation: https://docs.getdbt.com/docs/configuring-models

# In this example config, we tell dbt to build all models in the example/
# directory as views. These settings can be overridden in the individual model
# files using the `{{ config(...) }}` macro.


on-run-end: "{{ model_table_match() }}"

#seeds:
#  dbt_transform:
#    +catalog: "{{ env_var('DBX_UNITY_CATALOG') }}"
#    +schema: edp_dbt_ref_pipeline_raw
#    example:
#      +schema: edp_dbt_ref_pipeline_example

models:
  elementary:
    # elementary models will be created in the schema suffixed '_elementary'
    # See docs: https://docs.elementary-data.com/
    +catalog: "{{ env_var('DBX_UNITY_CATALOG') }}"
    +schema: "{{ env_var('DBX_ELEMENTARY_SCHEMA', default='elementary_not_used_locally') }}"
    ## Disable elementary only for local run
    +enabled: "{{ env_var('USER', default='')[0:4] in ['root', 'spar', 'runn'] }}"
  dbt_transform:
    +tblproperties:
      'delta.minReaderVersion': 2
      'delta.minWriterVersion': 5
      'delta.columnMapping.mode': 'name'
      'delta.enableChangeDataFeed': true
    +materialized: incremental
    #+cdf_incremental: false # Uncomment this to disable the CDF incremental logic for all models

    enriched_unharmonized:
      +schema: euh-ds-dbt
      +tags:
        - enriched_unharmonized
        - euh
    enriched_harmonized:
      +schema: eh-ds-dbt
      +tags:
        - enriched_harmonized
        - eh
    curated:
      +schema: curated-ds-dbt
      +tags:
        - curated
        - cu

    macro_unit_tests:
      +materialized: ephemeral
      +tags:
        - unit_test

snapshots:
  +tblproperties:
    'delta.minReaderVersion': 2
    'delta.minWriterVersion': 5
    'delta.columnMapping.mode': 'name'
    'delta.enableChangeDataFeed': true


vars:
  job_id: 'job id not available'
  run_id: 'run id not available'
  # Set schema_location:"n/a" if you don't have access rights to external location
  schema_location: "n/a"
  # Developer Sandbox, prefix schemas and/or tables with the developer name
  # If you can't create schemas set prefix_schema to False
  prefix: "{{ get_local_user_name() }}_"
  prefix_schema: False # Hard coded, Databricks workflow set to false.
  prefix_table: True # Hard coded, Databricks workflow set to false.
  load_type: 'delta'
  partition_var: 3
