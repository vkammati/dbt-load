name: "CD Deploy wheel and terraform"

on:
  workflow_call:
    inputs:
      environment:
        required: true
        type: string
      wheel_name:
        required: true
        type: string
      build_wheel_version:
        required: true
        type: string
      nr_of_wheels_to_keep:
        required: true
        type: number
      nr_of_days_to_keep_wheel:
        required: true
        type: number
      # Optionally, provide a json array with the names of one or more Databricks
      # Workflows that should be started after the deploy was succesfully completed.
      # This can also be specified in the job configuration yaml: databricks_dbt_job.yml
      databricks_workflows_to_start:
          required: false
          type: string
          default: "[]"

env:
  CATALOG_NAME_PLACEHOLDER: "##catalog_name_placeholder##"
  DBT_PROJECT_SUBFOLDER: dbt_transform

jobs:
  deploy:
    name: Deploy wheel and Terraform (${{ inputs.environment }})
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}

    env:
      # These environment variables can be used on both azure and aws
      CLIENT_ID: ${{ secrets.DEPLOY_SPN_CLIENT_ID }}
      CLIENT_SECRET: ${{ secrets.DEPLOY_SPN_CLIENT_SECRET }}
      # These environment variables are only used on Azure
      AZURE_TENANT_ID: ${{ secrets.DEPLOY_SPN_TENANT_ID }}
      AZURE_CLIENT_CERTIFICATE: ${{ secrets.DEPLOY_SPN_CLIENT_CERTIFICATE }}
      AZURE_CLIENT_CERTIFICATE_PASSWORD: ${{ secrets.DEPLOY_SPN_CLIENT_CERTIFICATE_PASSWORD }}

      # The next environment variables are all needed to run Terraform
      # The TF_WORKSPACE variable is used in conjuction with what is set as 'prefix' in
      # the provider.tf to determine the Terraform Cloud Workspace. Its value can also be
      # used in the Terraform module by using the 'terraform.workspace' variable.
      TF_WORKSPACE: ${{ inputs.environment }}
      DATABRICKS_HOST: ${{ vars.DBX_HOST }}
      TF_VAR_run_spn_client_id: ${{ secrets.RUN_SPN_CLIENT_ID }}
      TF_VAR_dbx_cluster_id: ${{ vars.DBX_CLUSTER_ID }}
      TF_VAR_dbx_http_path: ${{ vars.DBX_HTTP_PATH }}
      TF_VAR_dbx_unity_catalog: ${{ vars.DBX_UNITY_CATALOG }}
      TF_VAR_dbt_external_raw: "${{ vars.EXTERNAL_LOCATION_URL }}/${{ vars.AZ_SA_PATH_RAW }}"
      TF_VAR_dbt_external_euh: "${{ vars.EXTERNAL_LOCATION_URL }}/${{ vars.AZ_SA_PATH_EUH }}"
      TF_VAR_dbt_external_eh: "${{ vars.EXTERNAL_LOCATION_URL }}/${{ vars.AZ_SA_PATH_EH }}"
      TF_VAR_dbt_external_cur: "${{ vars.EXTERNAL_LOCATION_URL }}/${{ vars.AZ_SA_PATH_CUR }}"
      TF_VAR_dbt_external_elementary: "${{ vars.EXTERNAL_LOCATION_URL }}/${{ vars.AZ_SA_PATH_RAW }}.elementary"
      TF_VAR_external_location_url: ${{ vars.EXTERNAL_LOCATION_URL }}
      TF_VAR_dbt_landing_loc: ${{ vars.LANDING_LOCATION_URL }}
      TF_VAR_dbx_elementary_schema: ${{ vars.DBX_ELEMENTARY_SCHEMA }}
      TF_VAR_github_organisation: ${{ github.repository_owner }}
      TF_VAR_github_repository: ${{ github.event.repository.name }}
      TF_VAR_githubapp_id: ${{ vars.GITHUBAPP_ID }}
      TF_VAR_githubapp_private_key: ${{ secrets.GITHUBAPP_PRIVATE_KEY }}
      TF_VAR_edp_dbt_runner_wheel_version: ${{ inputs.build_wheel_version }}
      TF_VAR_teams_webhook_url: ${{vars.TEAMS_WEBHOOK_URL}}
      TF_VAR_run_spn_client_secret: ${{ secrets.RUN_SPN_CLIENT_SECRET }}
      TF_VAR_run_spn_tenant_id: ${{ secrets.RUN_SPN_TENANT_ID }}
      TF_VAR_storage_account: ${{ vars.AZ_SA_NAME }}


    steps:
        #First we deploy the wheel to the provided environment

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: v${{ inputs.build_wheel_version }}
          path: ./artifacts

      - name: Set SKIP_STEP variable
        run: |
          if [[ -z "${{ vars.DBX_HOST }}" || -z "${{ vars.DBX_HTTP_PATH }}" || -z "${{ vars.DBX_UNITY_CATALOG }}" || -z "${{ vars.DBX_ALEMBIC_SCHEMA }}" ]]; then
          echo "SKIP_STEP=true" >> $GITHUB_ENV
          else
          echo "SKIP_STEP=false" >> $GITHUB_ENV
          fi

      - name: Set up python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12.x"
          cache: 'pip' # caching pip dependencies

      - name: Install Python dependencies from requirements.txt
        run: |
          pip install -r ./artifacts/requirements.txt

      - name: Deploy wheel to Databricks workspace
        run: |
          python ./artifacts/.github/workflows/scripts/deploy_new_version.py \
            --wheel-name ${{ inputs.wheel_name }} \
            --source "./artifacts/dist/${{ inputs.wheel_name }}-${{ inputs.build_wheel_version }}-py3-none-any.whl"

      - name: Cleanup Databricks workspace
        run: |
          python ./artifacts/.github/workflows/scripts/cleanup_workspace.py \
            --wheel-name ${{ inputs.wheel_name }} \
            --nr-of-wheels-to-keep ${{ inputs.nr_of_wheels_to_keep }} \
            --nr-of-days-to-keep-wheel ${{ inputs.nr_of_days_to_keep_wheel }}

      # Next, terraform is used to create/update workflows and other assets
      - name: Get Databricks access token for Terraform deploy
        run: |
          echo "Getting access token"
          access_token=$(python ./artifacts/.github/workflows/scripts/get_access_token.py)
          echo "DATABRICKS_TOKEN=$access_token" >> "$GITHUB_ENV"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: 1.8.1
          cli_config_credentials_hostname: app.terraform.io
          cli_config_credentials_token: ${{ secrets.TFC_TOKEN }}

      - name: Init
        run: terraform init
        working-directory: ./artifacts/terraform

      - name: Refresh and Plan
        run: |
          terraform refresh
          terraform plan -input=false -lock=false
        working-directory: ./artifacts/terraform

      - name: Apply
        run: terraform apply -input=false -auto-approve
        working-directory: ./artifacts/terraform


      # Deploy dbt docs to github_pages branch
      - name: Check out
        uses: actions/checkout@v4
        with:
          path: ./repo

      # Run script to switch to github pages branch and, if it does not exists, create
      # it. Speifying 'bash' as the shell is necessary to grant the script execute
      # permission to be executed.
      - name: Switch to github_pages branch
        working-directory: ./repo
        run: bash ../artifacts/.github/workflows/scripts/switch_to_github_pages_branch.sh

      # Finally, Update the docs folder with the dbt docs from this build and commit.
      - name: Commit dbt docs to github_pages branch
        working-directory: ./repo
        # checks if static_index.html is present, if not it will not update dbt docs to github_pages branch
        run: |
          if [ -f '../artifacts/${{ env.DBT_PROJECT_SUBFOLDER }}/target/static_index.html' ]; then
            echo "Copying 'DBT Docs' to 'Docs' folder"

            mkdir -p ./docs/dbt_docs/${{ inputs.environment }} && cp ../artifacts/${{ env.DBT_PROJECT_SUBFOLDER }}/target/static_index.html "./docs/dbt_docs/${{ inputs.environment }}"

            echo "Replacing placeholder with catalog name"
            sed -i -e 's/${{ env.CATALOG_NAME_PLACEHOLDER }}/${{ vars.DBX_UNITY_CATALOG }}/g' "./docs/dbt_docs/${{ inputs.environment }}/static_index.html"

            echo "Comitting to branch"
            git config --global user.email "bot.noreply@shell.com"
            git config --global user.name "EDP Bot"
            git config --global --add --bool push.autoSetupRemote true
            git add ./docs/dbt_docs/${{ inputs.environment }}/static_index.html
            git commit -am "Updated 'DBT Docs' for '${{ inputs.environment }}' to '${{ inputs.build_wheel_version }}'" || exit 0
            git push
          else
            echo "::warning title="dbt docs NOT deployed"::"Skipped committing dbt docs as dbt docs are not generated in build phase because few variables are not configured""
          fi


      # Optionally, run Alembic to execute any DDL/DML post deployment statements. For
      # this, the run spn must be used as this one has access to the data.
      - name: Alembic deployment
        if: env.SKIP_STEP == 'false'
        env:
          CLIENT_ID: ${{ secrets.RUN_SPN_CLIENT_ID }}
          CLIENT_SECRET: ${{ secrets.RUN_SPN_CLIENT_SECRET }}
          AZURE_CLIENT_CERTIFICATE:
          DBX_HOST: ${{ vars.DBX_HOST }}
          DBX_HTTP_PATH: ${{ vars.DBX_HTTP_PATH }}
          DBX_UNITY_CATALOG: ${{ vars.DBX_UNITY_CATALOG }}
          DBX_ALEMBIC_SCHEMA: ${{ vars.DBX_ALEMBIC_SCHEMA }}
        run: |
          echo "Getting access token"
          export DBX_TOKEN=$(python ./.github/workflows/scripts/get_access_token.py)
          echo "Starting Alembic deployment"
          alembic upgrade head
        working-directory: ./artifacts

        # Finally and optionally, trigger a run for all provided Databricks Workflows.
        # This can be especially helpful for test runs on non-prod environments.
      - name: Start Databricks Workflow
        run: |
          python ./artifacts/.github/workflows/scripts/start_dbx_workflow.py \
            --workflow-names "${{ join(fromJSON(inputs.databricks_workflows_to_start), '" "') }}" \
            --workflow-definition-yaml-path "./artifacts/config/${{ inputs.environment }}/databricks_dbt_job.yml"
